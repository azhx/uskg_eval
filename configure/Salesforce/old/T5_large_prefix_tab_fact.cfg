[model]
name = unified.prefixtuning
use_description = False
concatenate_description = False
map_description = False
# Should be one of (separate, concatenate)
knowledge_usage = concatenate
# TODO
freeze_plm = True
# TODO
freeze_prefix = False

[dataset]
data_store_path = ./data
description_max_length = 64
#eval_num = 500
upsample_temp = 1

[seq2seq]
constructor = seq2seq_construction.meta_tuning
patience = 50

[arg_paths]
#e2e = META_TUNING/e2e.cfg
#sqa = META_TUNING/sqa.cfg
#spider = META_TUNING/spider.cfg
#dart = META_TUNING/dart.cfg
#cosql = META_TUNING/cosql.cfg
#logic2text = META_TUNING/logic2text.cfg
#wikisql = META_TUNING/wikisql.cfg
#wikitq = META_TUNING/wikitq.cfg
#webqsp = META_TUNING/webqsp.cfg
#fetaqa = META_TUNING/fetaqa.cfg
tab_fact = META_TUNING/tab_fact.cfg
#grailqa = META_TUNING/grailqa.cfg

[evaluate]
tool = metrics.meta_tuning.evaluator

[prefix_tuning]
# 10 previously.
prefix_sequence_length = 10
mid_dim = 512
prefix_dropout = 0.0

[special_tokens]
less = ' <'
less_or_equal = ' <='

[bert]
#location = tscholak/t5.1.1.lm100k.large
location = t5-large