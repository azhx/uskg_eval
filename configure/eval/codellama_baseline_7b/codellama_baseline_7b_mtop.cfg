[model]
name = "unified.llama_api"
use_description = false
concatenate_description = false
knowledge_usage = "concatenate"

[dataset]
data_store_path = "./data"

[seq2seq]
constructor = "seq2seq_construction.meta_tuning"
patience = 200

[arg_paths]
mtop = "META_TUNING/mtop.cfg"

[evaluate]
tool = "metrics.meta_tuning.no_evaluation"

[special_tokens]
less = " <"
less_or_equal = " <="

[bert]
location = "t5-3b"

[llama]
model_path = "/cpfs/29cd2992fe666f2a/shared/public/hub/models--codellama--CodeLlama-7b-Instruct-hf/snapshots/6114dd1e16f69e0765ccbd7a64d33d04b265fbd2"

[prompt_spec]
dataset_name = "mtop"
path = "./instuning_format_spec_eval.json"
few_shot_path = "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/one_shot_examples.json"

[debug]
dump_preds = true
