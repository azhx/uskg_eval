[model]
name = "unified.llama_api"
use_description = false
concatenate_description = false
knowledge_usage = "concatenate"

[dataset]
data_store_path = "./data"

[seq2seq]
constructor = "seq2seq_construction.meta_tuning"
patience = 200

[arg_paths]
grailqa = "META_TUNING/grailqa.cfg"

[evaluate]
tool = "metrics.meta_tuning.no_evaluation"

[special_tokens]
less = " <"
less_or_equal = " <="

[bert]
location = "t5-3b"

[llama]
model_path = "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/models/llama/v7_non_upsampled/checkpoint-2362"

[prompt_spec]
dataset_name = "grailqa"
path = "./instuning_format_spec_eval.json"
few_shot_path = "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/few_shot_examples_formatted.json"

[debug]
dump_preds = true
