# initial run on cosql of llama 2 chat

[model]
name = unified.llama_api
use_description = False
concatenate_description = False
# Should be one of (separate, concatenate)
knowledge_usage = concatenate

[dataset]
data_store_path = ./data

[seq2seq]
constructor = seq2seq_construction.meta_tuning
patience = 200

[arg_paths]
cosql = META_TUNING/cosql_with_cell.cfg

[evaluate]
tool = metrics.meta_tuning.evaluator

[special_tokens]
less = ' <'
less_or_equal = ' <='

[bert]
location = t5-3b

[llama]
url = "http://localhost:8090"
model_path = "/mnt/tjena/alex/llama2_chat_7_31" 
# must be a full absolute path

[prompt_spec]
dataset_name = 'cosql'
path = "/home/alex/v3-score/instuning_format_spec_eval.json"

[debug]
dump_preds = True
dump_preds_path = ./cosql_preds.pkl