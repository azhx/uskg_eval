[model]
name = unified.old_finetune # unused
use_description = True
concatenate_description = True
# Should be one of (separate, concatenate)
knowledge_usage = concatenate

[dataset]
data_store_path = ./data

# Larger upsample_temp leads to more uniform sampling
upsample_temp = 1

[seq2seq]
constructor = seq2seq_construction.meta_tuning
patience = 200

[arg_paths]
# Semantic parsing
# grailqa = META_TUNING/grailqa.cfg
cosql = META_TUNING/cosql_with_cell.cfg
sqa = META_TUNING/sqa.cfg
finqa = META_TUNING/finqa.cfg
infotabs = META_TUNING/infotabs.cfg
bird = META_TUNING/bird.cfg

spider = META_TUNING/spider_with_cell.cfg
mtop = META_TUNING/mtop.cfg
# # Question answering
wikitq = META_TUNING/wikitq.cfg
wikisql = META_TUNING/wikisql.cfg
hybridqa = META_TUNING/hybridqa.cfg
fetaqa = META_TUNING/fetaqa.cfg
# Data-to-text
dart = META_TUNING/dart.cfg
totto = META_TUNING/totto.cfg
# Conversational
multiwoz = META_TUNING/multiwoz.cfg
kvret = META_TUNING/kvret.cfg
sparc = META_TUNING/sparc_with_cell.cfg

tabmwp = META_TUNING/tabmwp.cfg
# Fact verification
tab_fact = META_TUNING/tab_fact.cfg
feverous = META_TUNING/feverous.cfg
# High-fidelity NLG
logic2text = META_TUNING/logic2text.cfg
sql2text = META_TUNING/sql2text.cfg

[evaluate]
tool = metrics.meta_tuning.no_evaluation

[special_tokens]
less = ' <'
less_or_equal = ' <='

[bert]
location = /cpfs/29cd2992fe666f2a/shared/public/self-ins/jiajun/t5-3b
# location = /cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/output/new_T5_3b_all_tasks/