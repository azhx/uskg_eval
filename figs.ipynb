{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "fixed_preds = pickle.load(open(\"fixed_preds.pkl\", \"rb\"))\n",
    "examples = pickle.load(open(\"fixed_preds_examples.pkl\", \"rb\"))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/ML-A100/team/mm/zhangge/gezhangmv/SKGLM/models/uskg-multitask\")\n",
    "\n",
    "# use multiple workers  to launch 16 process for tokenizer.batch_decode of fixed_preds\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import tqdm\n",
    "\n",
    "def batch_decode(preds, tokenizer, num_proc=16):\n",
    "    with Pool(num_proc) as p:\n",
    "        return list(tqdm.tqdm(p.imap(partial(tokenizer.decode, skip_special_tokens=True), preds), total=len(preds)))\n",
    "    \n",
    "fixed_preds_decoded = batch_decode(fixed_preds, tokenizer)\n",
    "\n",
    "import json\n",
    "predictions = fixed_preds_decoded\n",
    "with open(f\"output/v13_uskg_inst_test/predictions_predict.json\", \"w\") as f:\n",
    "                json.dump(\n",
    "                    [dict(**{\"prediction\": predictions[idx]}, **examples[idx]) for idx in range(len(predictions))],\n",
    "                    f,\n",
    "                    indent=4,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
